{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penguins Dataset\n",
    "For the KNN implementation, we will use the Palmer Archipelago (Antarctica) penguin dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### penguins_size.csv: Simplified data from original penguin data sets. Contains variables:\n",
    "\n",
    "- species: penguin species (Chinstrap, Ad√©lie, or Gentoo)\n",
    "- culmen_length_mm: culmen length (mm)\n",
    "- culmen_depth_mm: culmen depth (mm)\n",
    "- flipper_length_mm: flipper length (mm)\n",
    "- body_mass_g: body mass (g)\n",
    "- island: island name (Dream, Torgersen, or Biscoe) in the Palmer Archipelago (Antarctica)\n",
    "- sex: penguin sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding KNN\n",
    "We will start writing the prompt for chatGPT.  \n",
    "`without using scikit learning, write in python a KNN algorithm`\n",
    "\n",
    "- Sure, I can provide you with a basic implementation of the k-Nearest Neighbors (KNN) algorithm in Python without using scikit-learn. Here's a simple example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "    class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indices of the first k neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Return the most common class label\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "\n",
    "    # Example usage\n",
    "    if __name__ == \"__main__\":\n",
    "    # Sample data\n",
    "    X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y_train = np.array([0, 0, 1, 1])\n",
    "    \n",
    "    X_test = np.array([[2.5, 3.5], [1.5, 2.5]])\n",
    "    \n",
    "    # Create KNN classifier\n",
    "    knn = KNN(k=2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = knn.predict(X_test)\n",
    "    \n",
    "    print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a basic implementation of the KNN algorithm. Keep in mind that this implementation is not optimized for performance and doesn't include various optimizations and distance metrics available in libraries like scikit-learn. It's intended for educational purposes to understand the basic mechanics of the KNN algorithm."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
