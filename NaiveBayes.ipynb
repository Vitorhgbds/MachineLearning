{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water potability Dataset\n",
    "We will use a Water Potability dataset\n",
    "columns: \n",
    "- ph\n",
    "- Hardness\n",
    "- Solids\n",
    "- Chloramines\n",
    "- Sulfate\n",
    "- Conductivity\n",
    "- Organic_carbon \n",
    "- Trihalomethanes \n",
    "- Turbidity\n",
    "- Potability (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Naive Bayes\n",
    "We will start writing the prompt for chatGPT.  \n",
    "`write naive bayes algorithm without using scikit learning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and preprocess your dataset\n",
    "# Ensure you have X (features) and y (labels) prepared.\n",
    "\n",
    "# Step 2: Split your dataset into training and testing sets\n",
    "def train_test_split(X, y, test_size=0.3, random_seed=None):\n",
    "    if random_seed:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    test_samples = int(test_size * num_samples)\n",
    "    \n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    test_indices = indices[:test_samples]\n",
    "    train_indices = indices[test_samples:]\n",
    "    \n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Step 3: Implement Gaussian Naive Bayes\n",
    "\n",
    "def calculate_mean_std(X):\n",
    "    # Calculate mean and standard deviation for each feature in X\n",
    "    num_features = X.shape[1]\n",
    "    means = np.zeros(num_features)\n",
    "    stds = np.zeros(num_features)\n",
    "    \n",
    "    for feature in range(num_features):\n",
    "        feature_values = X[:, feature]\n",
    "        means[feature] = np.mean(feature_values)\n",
    "        stds[feature] = np.std(feature_values)\n",
    "    \n",
    "    return means, stds\n",
    "\n",
    "def gaussian_probability(x, mean, std):\n",
    "    # Calculate the Gaussian probability density function\n",
    "    exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "    return (1 / (std * np.sqrt(2 * np.pi))) * exponent\n",
    "\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    # Calculate class priors\n",
    "    unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "    priors = class_counts / len(y_train)\n",
    "    \n",
    "    # Calculate mean and standard deviation for each feature and class\n",
    "    num_classes = len(unique_classes)\n",
    "    num_features = X_train.shape[1]\n",
    "    means = np.zeros((num_classes, num_features))\n",
    "    stds = np.zeros((num_classes, num_features))\n",
    "    \n",
    "    for i, class_label in enumerate(unique_classes):\n",
    "        class_data = X_train[y_train == class_label]\n",
    "        means[i, :], stds[i, :] = calculate_mean_std(class_data)\n",
    "    \n",
    "    return priors, means, stds\n",
    "\n",
    "def predict_naive_bayes(X_test, priors, means, stds):\n",
    "    num_classes = len(priors)\n",
    "    num_samples = X_test.shape[0]\n",
    "    predictions = np.zeros((num_samples, num_classes))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_classes):\n",
    "            class_prior = np.log(priors[j])\n",
    "            likelihood = np.sum(np.log(gaussian_probability(X_test[i, :], means[j, :], stds[j, :])))\n",
    "            predictions[i, j] = class_prior + likelihood\n",
    "    \n",
    "    return np.argmax(predictions, axis=1)\n",
    "\n",
    "# Step 4: Train and test the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_seed=42)\n",
    "priors, means, stds = train_naive_bayes(X_train, y_train)\n",
    "y_pred = predict_naive_bayes(X_test, priors, means, stds)\n",
    "\n",
    "# Step 5: Evaluate the model (calculate accuracy, confusion matrix, etc.)\n",
    "# Implement evaluation metrics based on your specific problem and requirements."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
